{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "control =  pd.read_csv('data/control.csv', delimiter = ',')\n",
    "exposed =  pd.read_csv('data/exposed.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of yes in control: 264\n",
      "number of yes in experiment: 308\n"
     ]
    }
   ],
   "source": [
    "yes_cont=control['yes'].sum()\n",
    "yes_exp=exposed['yes'].sum()\n",
    "yes_total=yes_cont+yes_exp\n",
    "print (\"number of yes in control:\", yes_cont)\n",
    "print (\"number of yes in experiment:\" ,yes_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Control</th>\n",
       "      <th>Experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>264</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>322</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Control  Experiment\n",
       "Yes      264         308\n",
       "No       322         349"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {\"Control\":pd.Series([control.yes.sum(),control.no.sum()],\n",
    "                                  index = [\"Yes\",\"No\"]),\n",
    "           \"Experiment\":pd.Series([exposed.yes.sum(),exposed.no.sum()],\n",
    "                               index = [\"Yes\",\"No\"])}\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Control</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Total</th>\n",
       "      <th>Prob</th>\n",
       "      <th>StdErr</th>\n",
       "      <th>MargErr</th>\n",
       "      <th>CI_lower</th>\n",
       "      <th>CI_upper</th>\n",
       "      <th>Obs_val</th>\n",
       "      <th>Pass_Sanity</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>264</td>\n",
       "      <td>308</td>\n",
       "      <td>572</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.459024</td>\n",
       "      <td>0.540976</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>True</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>322</td>\n",
       "      <td>349</td>\n",
       "      <td>671</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.019302</td>\n",
       "      <td>0.037832</td>\n",
       "      <td>0.462168</td>\n",
       "      <td>0.537832</td>\n",
       "      <td>0.520119</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Control  Experiment  Total  Prob    StdErr   MargErr  CI_lower  CI_upper  \\\n",
       "Yes      264         308    572   0.5  0.020906  0.040976  0.459024  0.540976   \n",
       "No       322         349    671   0.5  0.019302  0.037832  0.462168  0.537832   \n",
       "\n",
       "      Obs_val  Pass_Sanity      Diff  \n",
       "Yes  0.538462         True  0.076923  \n",
       "No   0.520119         True  0.040238  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['Total']=df_results.Control + df_results.Experiment\n",
    "df_results['Prob'] = 0.5\n",
    "df_results['StdErr'] = np.sqrt((df_results.Prob * (1- df_results.Prob))/df_results.Total)\n",
    "df_results[\"MargErr\"] = 1.96 * df_results.StdErr\n",
    "df_results[\"CI_lower\"] = df_results.Prob - df_results.MargErr\n",
    "df_results[\"CI_upper\"] = df_results.Prob + df_results.MargErr\n",
    "df_results[\"Obs_val\"] = df_results.Experiment/df_results.Total\n",
    "df_results[\"Pass_Sanity\"] = df_results.apply(lambda x: (x.Obs_val > x.CI_lower) and (x.Obs_val < x.CI_upper),axis=1)\n",
    "df_results['Diff'] = abs((df_results.Experiment - df_results.Control)/df_results.Total)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2196969696969697 1.1331168831168832 1.0706726820183998 1.1955610842153666 0.03185928627473644 0.06244420109848343\n"
     ]
    }
   ],
   "source": [
    "control_yes = df_results.loc['Yes','Control']\n",
    "control_no = df_results.loc['No','Control']\n",
    "\n",
    "exp_yes = df_results.loc['Yes','Experiment']\n",
    "exp_no = df_results.loc['No', 'Experiment']\n",
    "\n",
    "## control value \n",
    "cont_p_hat = control_no/control_yes\n",
    "\n",
    "## observed value (experimental value)\n",
    "exp_p_hat = exp_no/exp_yes\n",
    "\n",
    "## Standard Error\n",
    "SE_Prob = np.sqrt(np.abs((cont_p_hat * (1- cont_p_hat))/control_yes))\n",
    "\n",
    "\n",
    "## margin of error for 95% confidence interval (z = 1.96)\n",
    "\n",
    "ME_Prob = SE_Prob * 1.96\n",
    "\n",
    "## CI\n",
    "upper_Prob = exp_p_hat + ME_Prob\n",
    "lower_Prob = exp_p_hat - ME_Prob\n",
    "\n",
    "## Sane in the membrane (yes, it passes)\n",
    "print(cont_p_hat,exp_p_hat,lower_Prob,upper_Prob, SE_Prob, ME_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-174b3b2b80cc>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_exposed_notnull_yes = exposed[pd.isnull(control.yes) != True]\n",
      "<ipython-input-39-174b3b2b80cc>:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_exposed_notnull_no = exposed[pd.isnull(control.no) != True]\n"
     ]
    }
   ],
   "source": [
    "df_control_notnull_yes = control[pd.isnull(control.yes) != True]\n",
    "df_exposed_notnull_yes = exposed[pd.isnull(control.yes) != True]\n",
    "\n",
    "df_control_notnull_no = control[pd.isnull(control.no) != True]\n",
    "df_exposed_notnull_no = exposed[pd.isnull(control.no) != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Control</th>\n",
       "      <th>Experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>264</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>322</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Control  Experiment\n",
       "Yes      264         308\n",
       "No       322         349"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_notnull = {\"Control\":pd.Series([df_control_notnull_yes.yes.sum(),df_control_notnull_no.no.sum()],\n",
    "                                  index = [\"Yes\",\"No\"]),\n",
    "           \"Experiment\":pd.Series([df_exposed_notnull_yes.yes.sum(),df_exposed_notnull_no.no.sum()],\n",
    "                               index = [\"Yes\",\"No\"])}\n",
    "df_results_notnull = pd.DataFrame(results_notnull)\n",
    "df_results_notnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_exp = df_results_notnull.loc[\"Yes\"].Experiment\n",
    "no_exp = df_results_notnull.loc[\"No\"].Experiment\n",
    "\n",
    "# control values\n",
    "\n",
    "yes_cont = df_results_notnull.loc[\"Yes\"].Control\n",
    "no_cont = df_results_notnull.loc[\"No\"].Control\n",
    "\n",
    "\n",
    "# metrics\n",
    "\n",
    "GrossConversion_exp = yes_exp/no_exp\n",
    "GrossConversion_cont = yes_cont/no_cont\n",
    "\n",
    "\n",
    "GrossConversion = (no_exp + yes_cont)/(no_exp + no_cont)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrossConversion: 0.9135618479880775 \n"
     ]
    }
   ],
   "source": [
    "print('GrossConversion: {} '.format(GrossConversion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8198757763975155"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GrossConversion_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8825214899713467"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GrossConversion_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_prop(p_hat,z_score,N_cont,N_exp,diff):\n",
    "    std_err = np.sqrt((p_hat * (1- p_hat ))*(1/N_cont + 1/N_exp))\n",
    "    marg_err = z_score * std_err\n",
    "    ci_lower = diff - marg_err\n",
    "    ci_upper = diff + marg_err\n",
    "    \n",
    "    return std_err,marg_err,ci_lower,ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0626457135738312"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GrossConversion_diff = GrossConversion_exp - GrossConversion_cont\n",
    "GrossConversion_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Sequential Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialTest:\n",
    "  def __init__(self,exposed,control,...):\n",
    "    '''\n",
    "    initialise startup variables\n",
    "    '''\n",
    "\n",
    "  \n",
    "  def stoppingRule(self, ...):\n",
    "    '''\n",
    "    This function should take current observation and return statistical decision made. \n",
    "    Consider truncate rule for longer tests\n",
    "    '''\n",
    "    S, a, b,\n",
    "\n",
    "  def computeBoundaries(self,):\n",
    "    '''\n",
    "    This function shoud compute boundaries \n",
    "    '''\n",
    "\n",
    "  def plotTest(self,):\n",
    "    '''\n",
    "    showing the cumulative statistical test (e.g., log probability ratio) and the uper and lower limits.\n",
    "    '''\n",
    "\n",
    "  def plotBoundaries(self,):\n",
    "    '''cumulative sums of exposed successes, bounded by the critical limits.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "  '''\n",
    "  segment data into exposed and control groups\n",
    "  consider that SmartAd runs the experment hourly, group data into hours. \n",
    "      Hint: create new column to hold date+hour and use df.column.map(lambda x:  pd.Timestamp(x,tz=None).strftime('%Y-%m-%d:%H'))\n",
    "  create two dataframes with bernouli series 1 for posetive(yes) and 0 for negative(no)\n",
    "    Hint: Given engagement(sum of yes and no until current observation as an array) and success (yes countas an array), the method generates random binomial distribution\n",
    "        #Example\n",
    "           engagement = np.array([5, 3, 3])\n",
    "           yes = np.array([2, 0, 3])       \n",
    "         Output is \"[1] 1 0 1 0 0 0 0 0 1 1 1\", showing a binary array of 5+3+3 values\n",
    "         of which 2 of the first 5 are ones, 0 of the next 3 are ones, and all 3 of\n",
    "         the last 3 are ones where position the ones is randomly distributed within each group.\n",
    "  '''\n",
    "  return exposed,control\n",
    "\n",
    "def plotDataSummary(exposed, control):\n",
    "  'This function plots cummulated success'\n",
    "\n",
    "def pretyPrintTestResult(self, test):\n",
    "  '''This function print final test result. Json format is recommended. For example\n",
    "  {\n",
    "    \"name\": \"\",\n",
    "    \"engagementCountControl\": ,\n",
    "    \"engagementCountExposed\": ,\n",
    "    \"positiveCountControl\": ,\n",
    "    \"positiveCountExposed\": ,\n",
    "    \"ControlSuccessProbability\": ,\n",
    "    \"ExposedSuccessProbability\": ,\n",
    "    \"basePositiveRate\": ,\n",
    "    \"significanceSign\": \".\",\n",
    "    \"lift\": ,\n",
    "    \"oddRatio\": ,\n",
    "    \"exactSuccessOddRate\":,\n",
    "    \"confidenceIntervalLevel\": ,\n",
    "    \"alpha\": ,\n",
    "    \"beta\": ,\n",
    "    \"power\": ,\n",
    "    \"criticalValue\": ,\n",
    "    \"lower critical(a)\": \n",
    "    \"upper critical(b)\": ,\n",
    "    \"TotalObservation\": \n",
    "  }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Define statistical parameters such as alpha, beta, sample size if evan approach is used, odd ratio for SPRT'\n",
    "alpha=\n",
    "beta=\n",
    "#other variables here\n",
    "'Compute statistical lower and upper decision points such as a and b'\n",
    "a=\n",
    "b=\n",
    "#other variables here\n",
    "\n",
    "##data processing here\n",
    "exposed,control=transform_data(data)\n",
    "##plot data summary\n",
    "plotDataSummary(exposed,control)\n",
    "\n",
    "'Perform test. Loop over each of data entry and perform test. Accumulate result into dataframe and print out test journey'\n",
    "test=SequentialTest(...)\n",
    "\n",
    "'Print test result.'\n",
    "pretyPrintTestResult(resultObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
